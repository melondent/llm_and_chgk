{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('questions_without_material.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "random.seed(42)\n",
    "random_sample = random.sample(data, 260)\n",
    "    \n",
    "   \n",
    "with open('random_sample_260.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(random_sample, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_sample_260.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан файл диссертация_разметка/данные/data_1.json с 52 вопросами\n",
      "Создан файл диссертация_разметка/данные/data_2.json с 52 вопросами\n",
      "Создан файл диссертация_разметка/данные/data_3.json с 52 вопросами\n",
      "Создан файл диссертация_разметка/данные/data_4.json с 52 вопросами\n",
      "Создан файл диссертация_разметка/данные/data_5.json с 52 вопросами\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 52\n",
    "total_chunks = 5\n",
    "\n",
    "for i in range(total_chunks):\n",
    "    start_index = i * chunk_size\n",
    "    end_index = start_index + chunk_size\n",
    "    chunk = data[start_index:end_index]\n",
    "    \n",
    "    output_filename = f'диссертация_разметка/данные/data_{i+1}.json'\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(chunk, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f'Создан файл {output_filename} с {len(chunk)} вопросами')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ответы на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. google/gemma-3-27b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 336,\n",
       " 'Пакет': 'Балтийский берег. IV тур',\n",
       " '№': 6.0,\n",
       " 'Вопрос': 'В одной книге, посвящённой истории медицины, приводится высказывание: «ОН – нянечка для бедняка». В девятнадцатом веке ЕГО действительно могли позволить себе даже представители рабочего класса. Назовите ЕГО.',\n",
       " 'Ответ': 'опиум',\n",
       " 'Зачет': 'лауданум.',\n",
       " 'Комментарий': 'вероятно, авторы книги отсылают к известной цитате «религия – опиум для народа». Чтобы успокоить кричащих младенцев, в девятнадцатом веке могли использовать опиумные настойки.',\n",
       " 'Источник': None,\n",
       " 'Авторы': 'Мария Подрядчикова (Волгоград)',\n",
       " 'Доля взятия': '674/1032',\n",
       " 'Процент взятия': 65.0,\n",
       " 'Год': '2019_2020'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('диссертация_разметка/данные/data_1.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    prompt = f\"\"\"Ты участвуешь в интеллектуальной игре. Пожалуйста, кратко порассуждай над следующим вопросом и дай ответ.\n",
    "\n",
    "Вопрос: {item['Вопрос']}\n",
    "\n",
    "Выведи рассуждение и ответ в формате JSON:\n",
    "{{\n",
    "    \"reasoning\": \"твои рассуждения здесь\",\n",
    "    \"answer\": \"ответ здесь\"\n",
    "}}\"\"\"\n",
    "\n",
    "    try:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "            model=\"google/gemma-3-27b-it\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            seed=1,\n",
    "            max_tokens=10000\n",
    "        )\n",
    "\n",
    "        \n",
    "        content = chat_completion.choices[0].message.content\n",
    "        \n",
    "        results.append({\n",
    "            \"model\": \"gemma-3\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"raw_model_response\": content\n",
    "        })\n",
    "        \n",
    "        #print(f\"\\n--- Вопрос {i+1} ---\\n{content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"model\": \"gemma-3\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        print(f\"Ошибка при обработке вопроса {i+1}: {e}\")\n",
    "\n",
    "    time.sleep(1.0)\n",
    "\n",
    "with open('диссертация_разметка/model_1_answers_raw.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Qwen/QwQ-32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2077,\n",
       " 'Пакет': 'Турнир «12 граней-2022». Вторая игра',\n",
       " '№': 34.0,\n",
       " 'Вопрос': 'Один писатель сравнил черноту ЧАДСКОГО АДА с влажно-блестящим живым Изидиным зрачком. Какие два слова мы заменили словами «ЧАДСКИЙ АД»?',\n",
       " 'Ответ': 'нильский ил',\n",
       " 'Зачет': 'ил Нила.',\n",
       " 'Комментарий': 'по мнению Дмитрия Мережковского, весь мир для Египтян - чернота нильского ила и краснота мёртвых песков.',\n",
       " 'Источник': None,\n",
       " 'Авторы': 'Василий Корягин (Тольятти), Дмитрий Балашов (Тольятти)',\n",
       " 'Доля взятия': '26/119',\n",
       " 'Процент взятия': 22.0,\n",
       " 'Год': '2022_2023'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('диссертация_разметка/данные/data_2.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    prompt = f\"\"\"Ты участвуешь в интеллектуальной игре. Пожалуйста, кратко порассуждай над следующим вопросом и дай ответ.\n",
    "\n",
    "Вопрос: {item['Вопрос']}\n",
    "\n",
    "Выведи рассуждение и ответ в формате JSON:\n",
    "{{\n",
    "    \"reasoning\": \"твои рассуждения здесь\",\n",
    "    \"answer\": \"ответ здесь\"\n",
    "}}\"\"\"\n",
    "\n",
    "    try:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "            model=\"Qwen/QwQ-32B\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            seed=1,\n",
    "            max_tokens=3000\n",
    "        )\n",
    "\n",
    "        content = chat_completion.choices[0].message.content\n",
    "        \n",
    "        results.append({\n",
    "            \"model\": \"QwQ\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"raw_model_response\": content\n",
    "        })\n",
    "        \n",
    "        #print(f\"\\n--- Вопрос {i+1} ---\\n{content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"model\": \"QwQ\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        print(f\"Ошибка при обработке вопроса {i+1}: {e}\")\n",
    "\n",
    "    time.sleep(1.0)\n",
    "\n",
    "with open('диссертация_разметка/model_2_answers_raw.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. microsoft/Phi-4-multimodal-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2297,\n",
       " 'Пакет': 'Лига Сибири. V тур',\n",
       " '№': 2.0,\n",
       " 'Вопрос': 'На международных соревнованиях по шахматам Оскару Роберто Панно зачастую лишь немного не хватало до первого места. Посвящённая Панно и его соотечественникам книга называется «ТАКОЕ поколение». Ответьте, какую страну представляли эти шахматисты, а также какое слово мы заменили словом ТАКОЕ.',\n",
       " 'Ответ': 'Аргентина, серебряное.',\n",
       " 'Зачет': None,\n",
       " 'Комментарий': 'в книге «Серебряное поколение» рассказывается об аргентинских шахматистах, занимавших вторые места на шахматных олимпиадах. Название страны «Аргентина» образовано от корня со значением «серебро».',\n",
       " 'Источник': 'https://en.chessbase.com/post/argentina-silver-generation',\n",
       " 'Авторы': 'Антон Саксонов (Санкт-Петербург)',\n",
       " 'Доля взятия': '165/280',\n",
       " 'Процент взятия': 59.0,\n",
       " 'Год': '2022_2023'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('диссертация_разметка/данные/data_3.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    prompt = f\"\"\"Ты участвуешь в интеллектуальной игре. Пожалуйста, кратко порассуждай над следующим вопросом и дай ответ.\n",
    "\n",
    "Вопрос: {item['Вопрос']}\n",
    "\n",
    "Выведи рассуждение и ответ в формате JSON:\n",
    "{{\n",
    "    \"reasoning\": \"твои рассуждения здесь\",\n",
    "    \"answer\": \"ответ здесь\"\n",
    "}}\"\"\"\n",
    "\n",
    "    try:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "            model=\"microsoft/Phi-4-multimodal-instruct\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            seed=1,\n",
    "            max_tokens=5000\n",
    "        )\n",
    "\n",
    "        content = chat_completion.choices[0].message.content\n",
    "        \n",
    "        results.append({\n",
    "            \"model\": \"Phi-4\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"raw_model_response\": content\n",
    "        })\n",
    "        \n",
    "        #print(f\"\\n--- Вопрос {i+1} ---\\n{content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"model\": \"Phi-4\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        print(f\"Ошибка при обработке вопроса {i+1}: {e}\")\n",
    "\n",
    "    time.sleep(1.0)\n",
    "\n",
    "with open('диссертация_разметка/model_3_answers_raw.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. meta-llama/Llama-4-Scout-17B-16E-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 484,\n",
       " 'Пакет': 'Балтийский Берег. II тур.',\n",
       " '№': 1.0,\n",
       " 'Вопрос': 'Коч – северное парусное судно, имевшее двойную обшивку и ставшее прообразом современного ледокола. Слово «коч» происходит от диалектного новгородского слова со значением «ОНА». ОНА входит в название блюда. Какого?',\n",
       " 'Ответ': 'селёдка под шубой',\n",
       " 'Зачет': 'точный ответ.',\n",
       " 'Комментарий': 'название «коч» происходит от диалектного новгородского «ко́ца» – шуба, что связано с обшивкой судна, укрепляющей его борта и защищающей от давления льда, да и просто от ударов.',\n",
       " 'Источник': 'http://flibusta.is/b/500678/read',\n",
       " 'Авторы': 'Александр Руденко (Минск)',\n",
       " 'Доля взятия': '832/963',\n",
       " 'Процент взятия': 86.0,\n",
       " 'Год': '2019_2020'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('диссертация_разметка/данные/data_4.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    prompt = f\"\"\"Ты участвуешь в интеллектуальной игре. Пожалуйста, кратко порассуждай над следующим вопросом и дай ответ.\n",
    "\n",
    "Вопрос: {item['Вопрос']}\n",
    "\n",
    "Выведи рассуждение и ответ в формате JSON:\n",
    "{{\n",
    "    \"reasoning\": \"твои рассуждения здесь\",\n",
    "    \"answer\": \"ответ здесь\"\n",
    "}}\"\"\"\n",
    "\n",
    "    try:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "            model=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            seed=1,\n",
    "            max_tokens=5000\n",
    "        )\n",
    "\n",
    "        content = chat_completion.choices[0].message.content\n",
    "        \n",
    "        results.append({\n",
    "            \"model\": \"Llama-4\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"raw_model_response\": content\n",
    "        })\n",
    "        \n",
    "        #print(f\"\\n--- Вопрос {i+1} ---\\n{content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"model\": \"Llama-4\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        print(f\"Ошибка при обработке вопроса {i+1}: {e}\")\n",
    "\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "with open('диссертация_разметка/model_4_answers_raw.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Qwen/Qwen3-32B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 2625,\n",
       " 'Пакет': 'Лига вузов. II тур',\n",
       " '№': 6.0,\n",
       " 'Вопрос': 'Внимание, в вопросе есть замена. Древняя Япония переняла многие элементы из культуры древнего Китая, однако часто они достигали Японии уже в изменённом виде. Говоря об этом, ведущий одного подкаста сравнивает древнюю Корею с НИМ. Некоторые англоязычные дети называют ЕГО «секретным сообщением». Назовите ЕГО двумя словами.',\n",
       " 'Ответ': 'испорченный телефон.',\n",
       " 'Зачет': 'сломанный телефон; по смыслу.',\n",
       " 'Комментарий': 'Корея располагается между Китаем и Японией. Многие китайские обычаи достигали Японии уже в видоизмененном корейцами виде, словно слова, прошедшие через испорченный телефон. В английском языке игру «испорченный телефон» чаще всего называют «chinese whispers» [чайни́з ви́сперс] — «китайский шёпот», но существует ряд альтернативных названий, например, «secret message» [сикрет мэссадж].',\n",
       " 'Источник': 'https://en.wikipedia.org/wiki/Chinese_whispers',\n",
       " 'Авторы': 'Валентин Копочель (Минск)',\n",
       " 'Доля взятия': '397/628',\n",
       " 'Процент взятия': 63.0,\n",
       " 'Год': '2023_2024'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('диссертация_разметка/данные/data_5.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    prompt = f\"\"\"Ты участвуешь в интеллектуальной игре. Пожалуйста, кратко порассуждай над следующим вопросом и дай ответ.\n",
    "\n",
    "Вопрос: {item['Вопрос']}\n",
    "\n",
    "Выведи рассуждение и ответ в формате JSON:\n",
    "{{\n",
    "    \"reasoning\": \"твои рассуждения здесь\",\n",
    "    \"answer\": \"ответ здесь\"\n",
    "}}\"\"\"\n",
    "\n",
    "    try:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "            model=\"Qwen/Qwen3-32B\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            seed=1,\n",
    "            max_tokens=3000\n",
    "        )\n",
    "\n",
    "        content = chat_completion.choices[0].message.content\n",
    "        \n",
    "        results.append({\n",
    "            \"model\": \"Qwen3\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"raw_model_response\": content\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n--- Вопрос {i+1} ---\\n{content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"model\": \"Qwen3\",\n",
    "            \"id\": item[\"id\"],\n",
    "            \"question\": item[\"Вопрос\"],\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        print(f\"Ошибка при обработке вопроса {i+1}: {e}\")\n",
    "\n",
    "    time.sleep(1.0)\n",
    "    \n",
    "with open('диссертация_разметка/model_5_answers_raw.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постобработка для всех ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(raw_response):\n",
    "    json_match = re.search(r'\\{[\\s\\S]*\\}', raw_response)\n",
    "    if not json_match:\n",
    "        return \"Ответ не дан\"\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(json_match.group(0))\n",
    "        return data.get(\"answer\", \"Ключ 'answer' не найден\")\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Ответ не дан\"\n",
    "\n",
    "processed_results = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    input_filename = f'диссертация_разметка/model_{i}_answers_raw.json'\n",
    "    try:\n",
    "        with open(input_filename, 'r', encoding='utf-8') as f:\n",
    "            raw_data = json.load(f)\n",
    "\n",
    "        for item in raw_data:\n",
    "            processed_results.append({\n",
    "                \"model\": item.get(\"model\", f\"model_{i}\"),\n",
    "                \"id\": item[\"id\"],\n",
    "                \"question\": item[\"question\"],\n",
    "                \"answer\": extract_answer(item[\"raw_model_response\"])\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в файле {input_filename}: {str(e)}\")\n",
    "\n",
    "with open('диссертация_разметка/answers_260.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(processed_results, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка ответов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. deepseek-ai/DeepSeek-R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\"\n",
    ")\n",
    "\n",
    "with open('random_sample_260.json') as f:\n",
    "    correct_data = json.load(f)\n",
    "\n",
    "with open('диссертация_разметка/answers_260.json') as f:\n",
    "    model_responses = json.load(f)\n",
    "\n",
    "\n",
    "model_responses_dict = {item['id']: item for item in model_responses}\n",
    "\n",
    "model_results = []\n",
    "for item in correct_data:\n",
    "    question_id = item['id']\n",
    "    model_response = model_responses_dict.get(question_id)\n",
    "    \n",
    "    if not model_response:\n",
    "        print(f\"Ответ для вопроса с ID {question_id} не найден\")\n",
    "        continue\n",
    "        \n",
    "    question = item['Вопрос']\n",
    "    model_answer = model_response['answer'].strip()\n",
    "    correct_answer = item['Ответ']\n",
    "    zachet = item['Зачет'].split(',') if item['Зачет'] else []\n",
    "\n",
    "    prompt = f\"\"\"Ты эксперт, оценивающий ответы в интеллектуальной игре. Оцени ответ:\n",
    "       true - ответ правильный, false - ответ неправильный.\n",
    "       \n",
    "    Вопрос: {question}\n",
    "    Ответ: {model_answer}\n",
    "\n",
    "    Правильный ответ: {correct_answer}\n",
    "    Допустимые варианты ответа, которые тоже засчитываются как верные: {', '.join(zachet) if zachet else 'Точный ответ'}\n",
    "\n",
    "    Верни JSON:\n",
    "    {{\n",
    "    \"is_correct\": true или false,\n",
    "    \"comment\": \"Краткое объяснение оценки\"\n",
    "    }}\"\"\"\n",
    "        \n",
    "    try:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "            model=\"deepseek-ai/DeepSeek-R1\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            seed=2,\n",
    "            temperature=0,\n",
    "            max_tokens=5000\n",
    "        )\n",
    "            \n",
    "        response_text = chat_completion.choices[0].message.content\n",
    "        \n",
    "        json_str = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        reasoning_match = re.search(r'<think>(.*?)</think>', response_text, re.DOTALL)\n",
    "        \n",
    "        if json_str:\n",
    "            evaluation = json.loads(json_str.group())\n",
    "            reasoning = reasoning_match.group(1).strip() if reasoning_match else \"\"\n",
    "        else:\n",
    "            evaluation = {\n",
    "                \"is_correct\": False,\n",
    "                \"comment\": \"Не удалось распознать оценку\"\n",
    "            }\n",
    "            reasoning = response_text\n",
    "            \n",
    "    except Exception as e:\n",
    "        evaluation = {\n",
    "            \"is_correct\": False,\n",
    "            \"comment\": f\"Ошибка при оценке: {str(e)}\",\n",
    "            \"raw\": response_text\n",
    "        }\n",
    "        reasoning = \"Произошла ошибка при запросе к API\"\n",
    "\n",
    "    model_results.append({\n",
    "        \"evaluation_model\": \"DeepSeek-R1\",\n",
    "        \"answer_model\": model_responses_dict.get(question_id)['model'],\n",
    "        \"question_id\": question_id,\n",
    "        \"question\": question,\n",
    "        \"model_answer\": model_answer,\n",
    "        \"correct_answer\": correct_answer,\n",
    "        \"zachet\": ', '.join(zachet) if zachet else 'Точный ответ',\n",
    "        \"evaluation\": evaluation,\n",
    "        \"reasoning\": reasoning\n",
    "    })\n",
    "\n",
    "    time.sleep(0.5) \n",
    "\n",
    "with open('диссертация_разметка/model_6_evaluation.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Оценка всех ответов завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. deepseek-ai/DeepSeek-V3-0324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка всех моделей завершена!\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=\"\",\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\"\n",
    ")\n",
    "\n",
    "with open('random_sample_260.json') as f:\n",
    "    correct_data = json.load(f)\n",
    "\n",
    "with open('диссертация_разметка/answers_260.json') as f:\n",
    "    model_responses = json.load(f)\n",
    "    \n",
    "\n",
    "model_responses_dict = {item['id']: item for item in model_responses}\n",
    "\n",
    "model_results = []\n",
    "for item in correct_data:\n",
    "    question_id = item['id']\n",
    "    model_response = model_responses_dict.get(question_id)\n",
    "    \n",
    "    if not model_response:\n",
    "        print(f\"Ответ для вопроса с ID {question_id} не найден\")\n",
    "        continue\n",
    "        \n",
    "    question = item['Вопрос']\n",
    "    model_answer = model_response['answer'].strip()\n",
    "    correct_answer = item['Ответ']\n",
    "    zachet = item['Зачет'].split(',') if item['Зачет'] else []\n",
    "\n",
    "    prompt = f\"\"\"Ты эксперт, оценивающий ответы в интеллектуальной игре. Оцени ответ:\n",
    "       true - ответ правильный, false - ответ неправильный.\n",
    "       \n",
    "    Вопрос: {question}\n",
    "    Ответ: {model_answer}\n",
    "\n",
    "    Правильный ответ: {correct_answer}\n",
    "    Допустимые варианты ответа, которые тоже засчитываются как верные: {', '.join(zachet) if zachet else 'Точный ответ'}\n",
    "\n",
    "    Верни JSON:\n",
    "    {{\n",
    "    \"is_correct\": true или false,\n",
    "    \"comment\": \"Краткое объяснение оценки\"\n",
    "    }}\"\"\"\n",
    "        \n",
    "    try:\n",
    "        chat_completion = openai.chat.completions.create(\n",
    "            model=\"deepseek-ai/DeepSeek-V3-0324\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            seed=2,\n",
    "            temperature=0,\n",
    "            max_tokens=5000\n",
    "        )\n",
    "            \n",
    "        response_text = chat_completion.choices[0].message.content\n",
    "        json_str = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if not json_str:\n",
    "            raise ValueError(\"Не найден JSON в ответе\")\n",
    "        \n",
    "        evaluation = json.loads(json_str.group())\n",
    "            \n",
    "    except Exception as e:\n",
    "            evaluation = {\n",
    "            \"is_correct\": False,\n",
    "            \"comment\": f\"Ошибка при оценке: {str(e)}\",\n",
    "            \"raw\": response_text\n",
    "        }\n",
    "        \n",
    "    model_results.append({\n",
    "        \"evaluation_model\": \"DeepSeek-V3\",\n",
    "        \"answer_model\": model_responses_dict.get(question_id)['model'],\n",
    "        \"question_id\": question_id,\n",
    "        \"question\": question,\n",
    "        \"model_answer\": model_answer,\n",
    "        \"correct_answer\": correct_answer,\n",
    "        \"zachet\": ', '.join(zachet) if zachet else 'Точный ответ',\n",
    "        \"evaluation\": evaluation\n",
    "    })\n",
    "        \n",
    "    time.sleep(1.0)\n",
    "    \n",
    "\n",
    "with open('диссертация_разметка/model_7_evaluation.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Оценка всех моделей завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=\"\")\n",
    "\n",
    "with open('random_sample_260.json', 'r', encoding='utf-8') as f:\n",
    "    correct_data = json.load(f)\n",
    "\n",
    "with open('диссертация_разметка/answers_260.json', 'r', encoding='utf-8') as f:\n",
    "    model_responses = json.load(f)\n",
    "\n",
    "model_responses_dict = {item['id']: item for item in model_responses}\n",
    "\n",
    "model_results = []\n",
    "\n",
    "for i, item in enumerate(correct_data, 1):\n",
    "    question_id = item['id']\n",
    "    model_response = model_responses_dict.get(question_id)\n",
    "    \n",
    "    if not model_response:\n",
    "        print(f\"[{i}/5] Ответ для вопроса с ID {question_id} не найден\")\n",
    "        continue\n",
    "        \n",
    "    question = item['Вопрос']\n",
    "    model_answer = model_response['answer'].strip()\n",
    "    correct_answer = item['Ответ']\n",
    "    zachet = item['Зачет'].split(',') if item['Зачет'] else []\n",
    "\n",
    "    prompt = f\"\"\"Ты эксперт, оценивающий ответы в интеллектуальной игре. Оцени ответ:\n",
    "true - ответ правильный, false - ответ неправильный.\n",
    "\n",
    "Вопрос: {question}\n",
    "Ответ: {model_answer}\n",
    "\n",
    "Правильный ответ: {correct_answer}\n",
    "Допустимые варианты ответа, которые тоже засчитываются как верные: {', '.join(zachet) if zachet else 'Точный ответ'}\n",
    "\n",
    "Верни JSON:\n",
    "{{\n",
    "  \"is_correct\": true или false,\n",
    "  \"comment\": \"Краткое объяснение оценки\"\n",
    "}}\"\"\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "            max_tokens=3000,\n",
    "            top_p=1,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "        json_str = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "\n",
    "        if json_str:\n",
    "            evaluation = json.loads(json_str.group())\n",
    "        else:\n",
    "            raise ValueError(\"Не удалось извлечь JSON из ответа\")\n",
    "\n",
    "    except Exception as e:\n",
    "        evaluation = {\n",
    "            \"is_correct\": False,\n",
    "            \"comment\": f\"Ошибка при оценке: {str(e)}\",\n",
    "            \"raw\": response_text if 'response_text' in locals() else \"\"\n",
    "        }\n",
    "\n",
    "    model_results.append({\n",
    "        \"question_id\": question_id,\n",
    "        \"question\": question,\n",
    "        \"model_answer\": model_answer,\n",
    "        \"correct_answer\": correct_answer,\n",
    "        \"zachet\": ', '.join(zachet) if zachet else 'Точный ответ',\n",
    "        \"evaluation\": evaluation\n",
    "    })\n",
    "\n",
    "    time.sleep(1.0) \n",
    "    #print(f\"Результат оценки: {evaluation['is_correct']} ({evaluation['comment']})\")\n",
    "\n",
    "output_path = 'диссертация_разметка/model_8_evaluation.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Результаты сохранены в: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ручная разметка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "def print_separator(title=None, width=80):\n",
    "    if title:\n",
    "        print(\"\\n\" + f\" {title} \".center(width, \"=\"))\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\" * width)\n",
    "\n",
    "def print_formatted(text, title=None, width=80):\n",
    "    if title:\n",
    "        print(f\"\\n{title}:\")\n",
    "        print(\"-\" * len(title))\n",
    "    for line in textwrap.wrap(text, width=width):\n",
    "        print(line)\n",
    "\n",
    "def save_results(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\nАвтосохранение: результаты сохранены в {filename}\")\n",
    "\n",
    "with open('random_sample_260.json') as f:\n",
    "    correct_data = json.load(f)\n",
    "\n",
    "with open('диссертация_разметка/answers_260.json') as f:\n",
    "    model_responses = json.load(f)\n",
    "\n",
    "model_responses_dict = {item['id']: item for item in model_responses}\n",
    "human_evaluations = []\n",
    "output_file = 'диссертация_разметка/human_evaluation_results_1.json'\n",
    "autosave_interval = 10  # Сохранять каждые 10 вопросов\n",
    "\n",
    "print_separator(\" ОЦЕНКА ОТВЕТОВ МОДЕЛИ ЧЕЛОВЕКОМ \")\n",
    "print(f\"Инструкция: вводите 1 если ответ правильный, 0 если неправильный\")\n",
    "print(f\"Результаты будут автоматически сохраняться каждые {autosave_interval} вопросов\")\n",
    "input(\"\\nНажмите Enter чтобы начать...\")\n",
    "\n",
    "for idx, item in enumerate(correct_data, 1):\n",
    "    question_id = item['id']\n",
    "    model_response = model_responses_dict.get(question_id)\n",
    "    \n",
    "    if not model_response:\n",
    "        print(f\"\\n⚠ Ответ для вопроса с ID {question_id} не найден\")\n",
    "        continue\n",
    "    \n",
    "    print_separator(f\" ВОПРОС {idx}/{len(correct_data)} \")\n",
    "    \n",
    "    print(f\"\\nID вопроса: {question_id}\")\n",
    "    print_formatted(item['Вопрос'], \"Вопрос\")\n",
    "    print_formatted(model_response['answer'].strip(), \"Ответ модели\")\n",
    "    print_formatted(item['Ответ'], \"Правильный ответ\")\n",
    "    \n",
    "    if item['Зачет']:\n",
    "        print_formatted(\", \".join(item['Зачет'].split(',')), \"Допустимые варианты\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            rating = input(\"\\nОценка (1 - верно, 0 - неверно): \").strip()\n",
    "            rating = int(rating)\n",
    "            if rating not in [0, 1]:\n",
    "                raise ValueError\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Ошибка! Пожалуйста, введите 1 или 0\")\n",
    "    \n",
    "    comment = input(\"Комментарий (необязательно): \").strip()\n",
    "    \n",
    "    human_evaluations.append({\n",
    "        \"model_name\": model_response['model'],\n",
    "        \"question_id\": question_id,\n",
    "        \"question\": item['Вопрос'],\n",
    "        \"model_answer\": model_response['answer'].strip(),\n",
    "        \"correct_answer\": item['Ответ'],\n",
    "        \"zachet\": item['Зачет'],\n",
    "        \"human_score\": bool(rating),\n",
    "        \"human_comment\": comment if comment else None,\n",
    "    })\n",
    "\n",
    "    # Периодическое сохранение\n",
    "    if idx % autosave_interval == 0:\n",
    "        save_results(human_evaluations, output_file)\n",
    "        print_separator(f\" ПРОГРЕСС: {idx}/{len(correct_data)} \")\n",
    "        input(\"Нажмите Enter чтобы продолжить...\")\n",
    "\n",
    "save_results(human_evaluations, output_file)\n",
    "\n",
    "print_separator(\" ОЦЕНКА ЗАВЕРШЕНА! \")\n",
    "print(f\"Все результаты сохранены в файл: {output_file}\")\n",
    "print_separator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценивание экспертов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 accuracy: 97.31%\n",
      "Model 7 accuracy: 99.23%\n",
      "Model 8 accuracy: 99.62%\n",
      "Наиболее согласованная модель: model_8 (99.62%)\n"
     ]
    }
   ],
   "source": [
    "human_data = json.load(open(\"диссертация_разметка/human_evaluation_results.json\"))\n",
    "model_6_data = json.load(open(\"диссертация_разметка/model_6_evaluation.json\"))\n",
    "model_7_data = json.load(open(\"диссертация_разметка/model_7_evaluation.json\"))\n",
    "model_8_data = json.load(open(\"диссертация_разметка/model_8_evaluation.json\"))\n",
    "\n",
    "def compare_with_human(model_data, human_data):\n",
    "    matches = 0\n",
    "    total = 0\n",
    "    \n",
    "    human_dict = {item[\"question_id\"]: item for item in human_data}\n",
    "    \n",
    "    for model_item in model_data:\n",
    "        q_id = model_item[\"question_id\"]\n",
    "        if q_id in human_dict:\n",
    "            human_eval = human_dict[q_id]\n",
    "            model_is_correct = model_item[\"evaluation\"][\"is_correct\"]\n",
    "            human_is_correct = human_eval[\"human_score\"]\n",
    "            \n",
    "            if model_is_correct == human_is_correct:\n",
    "                matches += 1\n",
    "            total += 1\n",
    "    \n",
    "    return matches / total if total > 0 else 0\n",
    "\n",
    "accuracy_6 = compare_with_human(model_6_data, human_data)\n",
    "accuracy_7 = compare_with_human(model_7_data, human_data)\n",
    "accuracy_8 = compare_with_human(model_8_data, human_data)\n",
    "\n",
    "print(f\"Model 6 accuracy: {accuracy_6:.2%}\")\n",
    "print(f\"Model 7 accuracy: {accuracy_7:.2%}\")\n",
    "print(f\"Model 8 accuracy: {accuracy_8:.2%}\")\n",
    "\n",
    "best_model = max(\n",
    "    [(\"model_6\", accuracy_6), (\"model_7\", accuracy_7), (\"model_8\", accuracy_8)],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "print(f\"Наиболее согласованная модель: {best_model[0]} ({best_model[1]:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Расхождения для model_6 (всего: 7) ===\n",
      "\n",
      "ID вопроса: 978\n",
      "Вопрос: Несмотря на то, что ваянг-кулит является ИМ, там используются ярко окрашенные куклы. Назовите ЕГО двумя словами, которые начинаются на одни и те же буквы.\n",
      "Ответ модели: Теневой Театр\n",
      "Правильный ответ: театр теней.\n",
      "Оценка модели: False (комментарий: Правильный ответ — «театр теней». Хотя оба слова в ответе участника начинаются на «т», порядок слов не соответствует общепринятому названию. «Теневой театр» — описательное выражение, а не точный термин.)\n",
      "Оценка человека: True (комментарий: None)\n",
      "\n",
      "ID вопроса: 427\n",
      "Вопрос: Согласно результатам исследования Винанда А. Тилбурга, окружающие выше оценивают интеллектуальные способности и статус людей с ЭТИМ. Какое ЭТО есть в вопросе?\n",
      "Ответ модели: очками\n",
      "Правильный ответ: А\n",
      "Оценка модели: True (комментарий: Ответ верен. Исследование Винанда А. Тилбурга действительно показало, что люди в очках воспринимаются как более интеллектуальные и статусные. Слово «очками» присутствует в вопросе как ключевой элемент («ЭТИМ»).)\n",
      "Оценка человека: False (комментарий: None)\n",
      "\n",
      "ID вопроса: 1675\n",
      "Вопрос: Исландцы, славившиеся любовью к приключениям, неуважительно относились к дедам и называли их словом, которое буквально означает «кусающий угли». Напишите в исходном виде слово, в котором мы пропустили несколько букв.\n",
      "Ответ модели: Ответ не дан\n",
      "Правильный ответ: домоседам\n",
      "Оценка модели: True (комментарий: Правильный ответ 'домоседам' связан с метафорой: сидящий у очага (кусающий угли) символизирует домоседа. Исландское прозвище отражает пренебрежение к тем, кто избегает приключений, предпочитая оставаться дома.)\n",
      "Оценка человека: False (комментарий: None)\n",
      "\n",
      "ID вопроса: 2079\n",
      "Вопрос: Летом 2019 года российская фотохудожница представила проект из трёх снимков: на первом - фон преимущественно зелёный, на третьем – преимущественно чёрный. Мы не спрашиваем вас о цвете второго снимка, ответьте, чему посвящён описанный проект.\n",
      "Ответ модели: Проект посвящён циклу жизни или контрасту между жизнью и смертью.\n",
      "Правильный ответ: лесные пожары (в Сибири)\n",
      "Оценка модели: True (комментарий: Ответ верен по смыслу: зелёный (жизнь/лес) и чёрный (смерть/разрушение) символически отражают тему лесных пожаров, хотя прямо не названы. Проект действительно связан с экологической катастрофой в Сибири, но обобщение до контраста жизни и смерти допустимо.)\n",
      "Оценка человека: False (комментарий: None)\n",
      "\n",
      "ID вопроса: 1288\n",
      "Вопрос: Изобретение чего, по мнению американского писателя, стало декларацией независимости от божьего гнева?\n",
      "Ответ модели: Молниеотвод\n",
      "Правильный ответ: молниеотвода\n",
      "Оценка модели: False (комментарий: Ответ участника «Молниеотвод» в именительном падеже не совпадает с правильным ответом «молниеотвода» (родительный падеж). Хотя по смыслу ответ верен, формально требуется указание объекта в родительном падеже. Допустимый вариант «громоотвода» также в родительном падеже.)\n",
      "Оценка человека: True (комментарий: None)\n",
      "\n",
      "ID вопроса: 1624\n",
      "Вопрос: Внимание, в вопросе есть замены. Философ ВольтЕр признавал прусского короля ФрИдриха Второго достойным собеседником и называл его ТАКИМ ИКСОМ. Несколько ТАКИХ ИКСОВЫХ островов сейчас образуют автономный регион. Какие два слова, начинающиеся на одну и ту же букву, заменены ТАКИМ ИКСОМ?\n",
      "Ответ модели: Ответ не дан\n",
      "Правильный ответ: северный СоломОн.\n",
      "Оценка модели: True (комментарий: Правильный ответ: 'северный Соломон'. Вольтер называл Фридриха II 'северным Соломоном' за мудрость, а Соломоновы острова образуют автономный регион. Оба слова начинаются на 'с'.)\n",
      "Оценка человека: False (комментарий: None)\n",
      "\n",
      "ID вопроса: 2494\n",
      "Вопрос: В своей научной статье Наталья Северова пишет, что новые увольнения появляются из-за роста темпа жизни и желания ускорить процесс диалога между людьми. Какое слово в вопросе заменено другим?\n",
      "Ответ модели: диалог\n",
      "Правильный ответ: сокращения.\n",
      "Оценка модели: True (комментарий: Ответ верен: слово «диалог» заменяет правильный термин «сокращения», так как контекст статьи связан с увольнениями, а не с коммуникацией.)\n",
      "Оценка человека: False (комментарий: None)\n",
      "\n",
      "=== Расхождения для model_7 (всего: 2) ===\n",
      "\n",
      "ID вопроса: 2996\n",
      "Вопрос: Художница Мия Андо выросла среди буддистов. Её работа «Восьмеричный путь» выставлялась в одном из музеев таким образом, чтобы любой желающий мог сесть напротив этой работы и какое-то время ДЕЛАТЬ ЭТО. Какое слово латинского происхождения мы заменили словами ДЕЛАТЬ ЭТО?\n",
      "Ответ модели: meditari\n",
      "Правильный ответ: медитировать\n",
      "Оценка модели: True (комментарий: Ответ 'meditari' является латинским корнем слова 'медитировать', что соответствует контексту вопроса о буддистской практике и работе художницы.)\n",
      "Оценка человека: False (комментарий: None)\n",
      "\n",
      "ID вопроса: 1520\n",
      "Вопрос: Портрет Тадеуша Лемпицкого принадлежит кисти его жены Тамары. Во время написания портрета Тадеуш подал на развод и картина осталась незаконченной. Какая часть тела на портрете не дописана?\n",
      "Ответ модели: руки\n",
      "Правильный ответ: левая рука.\n",
      "Оценка модели: True (комментарий: Ответ 'руки' частично соответствует допустимым вариантам, так как подразумевает кисть или руку, но не уточняет сторону. Однако, учитывая контекст, его можно считать верным.)\n",
      "Оценка человека: False (комментарий: None)\n",
      "\n",
      "=== Расхождения для model_8 (всего: 1) ===\n",
      "\n",
      "ID вопроса: 427\n",
      "Вопрос: Согласно результатам исследования Винанда А. Тилбурга, окружающие выше оценивают интеллектуальные способности и статус людей с ЭТИМ. Какое ЭТО есть в вопросе?\n",
      "Ответ модели: очками\n",
      "Правильный ответ: А\n",
      "Оценка модели: True (комментарий: Ответ 'очками' соответствует правильному ответу 'А' и точно отражает суть исследования Винанда А. Тилбурга о влиянии очков на восприятие интеллектуальных способностей и статуса.)\n",
      "Оценка человека: False (комментарий: None)\n"
     ]
    }
   ],
   "source": [
    "def find_disagreements(model_data, human_data, model_name):\n",
    "    disagreements = []\n",
    "    human_dict = {item[\"question_id\"]: item for item in human_data}\n",
    "    \n",
    "    for model_item in model_data:\n",
    "        q_id = model_item[\"question_id\"]\n",
    "        if q_id in human_dict:\n",
    "            human_eval = human_dict[q_id]\n",
    "            model_is_correct = model_item[\"evaluation\"][\"is_correct\"]\n",
    "            human_is_correct = human_eval[\"human_score\"]\n",
    "            \n",
    "            if model_is_correct != human_is_correct:\n",
    "                disagreements.append({\n",
    "                    \"question_id\": q_id,\n",
    "                    \"question\": human_eval[\"question\"],\n",
    "                    \"model_answer\": model_item[\"model_answer\"],\n",
    "                    \"correct_answer\": human_eval[\"correct_answer\"],\n",
    "                    \"model_evaluation\": model_is_correct,\n",
    "                    \"human_evaluation\": human_is_correct,\n",
    "                    \"model_comment\": model_item[\"evaluation\"].get(\"comment\", \"\"),\n",
    "                    \"human_comment\": human_eval.get(\"human_comment\", \"\")\n",
    "                })\n",
    "    \n",
    "    return disagreements\n",
    "\n",
    "# Находим расхождения для каждой модели\n",
    "disagreements_6 = find_disagreements(model_6_data, human_data, \"model_6\")\n",
    "disagreements_7 = find_disagreements(model_7_data, human_data, \"model_7\")\n",
    "disagreements_8 = find_disagreements(model_8_data, human_data, \"model_8\")\n",
    "\n",
    "# Выводим результаты\n",
    "def print_disagreements(disagreements, model_name):\n",
    "    print(f\"\\n=== Расхождения для {model_name} (всего: {len(disagreements)}) ===\")\n",
    "    for item in disagreements:\n",
    "        print(f\"\\nID вопроса: {item['question_id']}\")\n",
    "        print(f\"Вопрос: {item['question']}\")\n",
    "        print(f\"Ответ модели: {item['model_answer']}\")\n",
    "        print(f\"Правильный ответ: {item['correct_answer']}\")\n",
    "        print(f\"Оценка модели: {item['model_evaluation']} (комментарий: {item['model_comment']})\")\n",
    "        print(f\"Оценка человека: {item['human_evaluation']} (комментарий: {item['human_comment']})\")\n",
    "\n",
    "print_disagreements(disagreements_6, \"model_6\")\n",
    "print_disagreements(disagreements_7, \"model_7\")\n",
    "print_disagreements(disagreements_8, \"model_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Каппа Коэна для model_6: 0.858\n",
      "Каппа Коэна для model_7: 0.959\n",
      "Каппа Коэна для model_8: 0.979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def calculate_kappa(model_data, human_data):\n",
    "    human_dict = {item[\"question_id\"]: item for item in human_data}\n",
    "    \n",
    "    model_scores = []\n",
    "    human_scores = []\n",
    "    \n",
    "    for model_item in model_data:\n",
    "        q_id = model_item[\"question_id\"]\n",
    "        if q_id in human_dict:\n",
    "            human_eval = human_dict[q_id]\n",
    "            model_scores.append(model_item[\"evaluation\"][\"is_correct\"])\n",
    "            human_scores.append(human_eval[\"human_score\"])\n",
    "    \n",
    "    if len(model_scores) > 0:\n",
    "        kappa = cohen_kappa_score(human_scores, model_scores)\n",
    "        return kappa\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Считаем каппу для каждой модели\n",
    "kappa_6 = calculate_kappa(model_6_data, human_data)\n",
    "kappa_7 = calculate_kappa(model_7_data, human_data)\n",
    "kappa_8 = calculate_kappa(model_8_data, human_data)\n",
    "\n",
    "print(f\"Каппа Коэна для model_6: {kappa_6:.3f}\")\n",
    "print(f\"Каппа Коэна для model_7: {kappa_7:.3f}\")\n",
    "print(f\"Каппа Коэна для model_8: {kappa_8:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
